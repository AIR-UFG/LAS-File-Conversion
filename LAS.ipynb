{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f4a680-6b21-4852-946f-fd6932c42bf8",
   "metadata": {},
   "source": [
    "# LAS Conversion Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85bd2ed-29d9-4658-b622-26822151f038",
   "metadata": {},
   "source": [
    "## SemanticKITTI Style (.bin & .label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b72e13-d350-474c-9a56-ccbb23f9063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "velodyne_path = \"/path/to/velodyne/\"\n",
    "labels_path = \"/path/to/labels/\"\n",
    "\n",
    "# Files\n",
    "bin_files = sorted(glob.glob(os.path.join(velodyne_path, \"*.bin\")))\n",
    "label_files = sorted(glob.glob(os.path.join(labels_path, \"*.label\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152378a-2722-4f05-9fec-2b8e2e0341b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & apply poses\n",
    "poses = np.loadtxt(\"/path/to/pose.txt\").reshape(-1, 3, 4)  # shape (N, 3, 4)\n",
    "poses_hom = np.zeros((poses.shape[0], 4, 4))\n",
    "poses_hom[:, :3, :4] = poses\n",
    "poses_hom[:, 3, 3] = 1.0 \n",
    "\n",
    "\n",
    "def transform_points(points, pose):\n",
    "    ones = np.ones((points.shape[0], 1))\n",
    "    points_hom = np.hstack([points, ones])  # (N, 4)\n",
    "    transformed = (pose @ points_hom.T).T\n",
    "    return transformed[:, :3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0cfbc5-b0a8-480b-b409-72e0f53e78e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists for every field of the combined sequence of .bin and .label for a standard point_format=3 LAS file\n",
    "all_x = []\n",
    "all_y = []\n",
    "all_z = []\n",
    "all_intensity = []\n",
    "all_semantic = []\n",
    "all_instance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00adc41d-1289-44f0-9f60-b4f80291e5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (bin_file, label_file) in enumerate(zip(bin_files, label_files)):\n",
    "    points = np.fromfile(bin_file, dtype=np.float32).reshape(-1, 4)\n",
    "    labels = np.fromfile(label_file, dtype=np.uint32)\n",
    "\n",
    "    points = np.nan_to_num(points, nan=0.0) # comment this if not needed\n",
    "    semantic = labels & 0xFFFF\n",
    "    instance = labels >> 16\n",
    "\n",
    "    # LAS classification field requires 5 bits, so a remap might be needed\n",
    "    mapping = {0: 0, 1: 1, 10: 2, 30: 3, 40: 4, 70: 5, 72: 6, 80: 7}  # Aircloud remap\n",
    "    mapped_labels = np.vectorize(mapping.get)(semantic)\n",
    "    transformed = transform_points(points[:,:3], poses_hom[idx])\n",
    "    \n",
    "    all_x.append(transformed[:, 0])\n",
    "    all_y.append(transformed[:, 1])\n",
    "    all_z.append(transformed[:, 2])\n",
    "    all_intensity.append((points[:, 3]).astype(np.uint16))\n",
    "    all_semantic.append(mapped_labels)\n",
    "    all_instance.append(instance % 256)  # for user_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc3250-44d2-463d-b32f-b64dac205151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all together\n",
    "x = np.concatenate(all_x)\n",
    "y = np.concatenate(all_y)\n",
    "z = np.concatenate(all_z)\n",
    "intensity = np.concatenate(all_intensity)\n",
    "classification = np.concatenate(all_semantic)\n",
    "user_data = np.concatenate(all_instance).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4ae26-2f26-40e4-abef-37979a023a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the LAS fields\n",
    "header = laspy.LasHeader(point_format=3, version=\"1.4\")\n",
    "header.x_scale = header.y_scale = header.z_scale = 0.01\n",
    "las = laspy.LasData(header)\n",
    "las.x = x\n",
    "las.y = y\n",
    "las.z = z\n",
    "las.intensity = intensity\n",
    "las.classification = classification\n",
    "las.user_data = user_data\n",
    "\n",
    "las.write(\"my_file.las\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cb9047-71e4-4bca-b2b7-78ca7c0b88cf",
   "metadata": {},
   "source": [
    "In case of lack of poses.txt, look for x/y/z_offset fields for manual configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16eaab0-e207-4181-ad12-e55f81fa1ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "las_file = laspy.read(\"my_file.las\")\n",
    "las_file.header, las_file.point_format.dimension_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
